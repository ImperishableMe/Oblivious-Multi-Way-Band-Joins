%----------------------------------------------------------------------
\chapter{Detailed Algorithm}
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\section{Algorithm Overview and Notation}
%----------------------------------------------------------------------

Our oblivious multi-way band join algorithm operates on acyclic join trees in four distinct phases, each maintaining data-independent access patterns while computing the complete join result.

\subsection{Algorithm Input and Output}

The algorithm takes as input a join tree $T = (V, E)$ where $V$ are table nodes and $E$ are join edges, along with tables $\{R_1, R_2, \ldots, R_k\}$ where each $R_i$ corresponds to node $v_i \in V$. For each edge $(v_i, v_j) \in E$, band join constraints specify predicates between join attributes. The algorithm produces as output an oblivious join result table $R_{result}$ containing all tuples satisfying the multi-way band join constraints.

\subsection{Table Type Definitions}

Following Krastnikov et al.'s terminology~\cite{krastnikov2020}, we distinguish between different types of tables based on their state in the algorithm:

\begin{itemize}
\item \textbf{\inputtables}: Original unmodified tables $\{R_1, R_2, \ldots, R_k\}$ as provided to the algorithm
\item \textbf{\augmentedtables}: \inputtables\ extended with persistent multiplicity metadata 
\item \textbf{\combinedtables}: Arrays of entries from multiple \augmentedtables\ with temporary metadata, sorted by join attribute for dual-entry processing
\item \textbf{\expandedtables}: \augmentedtables\ where each tuple appears exactly $\finalmult$ times
\item \textbf{\alignedtables}: \expandedtables\ reordered to enable correct concatenation for join result construction
\end{itemize}

\begin{table}[!htbp]
\centering
\caption{Table Schema Evolution Throughout Algorithm Phases}
\label{tab:table-schemas}
\small
\begin{tabular}{|p{2cm}|p{3.5cm}|p{3.5cm}|p{3cm}|}
\hline
\textbf{Type} & \textbf{Original Attrs} & \textbf{Persistent Meta} & \textbf{Temporary Meta} \\
\hline
$R_{input}$ & $\{a_1, a_2, \ldots, a_n\}$ & No & No \\
\hline
$R_{aug}$ & $\{a_1, a_2, \ldots, a_n\}$ & Yes & No \\
\hline
$\Rcomb$ & $\{\fieldtype, \joinattr, \fielddata\}$ & Yes & Yes \\
\hline
$R_{exp}$ & $\{a_1, a_2, \ldots, a_n\}$ & Yes & No \\
\hline
$R_{align}$ & $\{a_1, a_2, \ldots, a_n\}$ & Yes & No \\
\hline
\end{tabular}
\end{table}

\textbf{Metadata presence indicators:}
\begin{itemize}
\item \textbf{Persistent Meta}: Whether table contains metadata that carries forward through phases ($\fieldindex$, $\localmult$, $\finalmult$, $\foreignsum$)
\item \textbf{Temporary Meta}: Whether table contains metadata used only during specific computations. Combined tables use either $\localcumsum$ (bottom-up) or $\foreigncumsum$ (top-down), not both simultaneously
\item \textbf{Note}: Combined tables have a special dual-entry structure where original attributes are transformed into $\{\fieldtype, a, \fielddata\}$ format
\end{itemize}

\subsection{Data Structures and Notation}

The following table summarizes the key data structures, variables, and notation used throughout our oblivious multi-way band join algorithm. The notation distinguishes between entry type constants (using $\tau$ symbols), field accessors for tuple metadata, and various counter variables used in multiplicity computation.

\begin{table}[!htbp]
\centering
\caption{Algorithm Data Structures and Notation}
\label{tab:algorithm-notation}
\small
\begin{tabular}{|p{2.5cm}|p{9.5cm}|}
\hline
\textbf{Notation} & \textbf{Description} \\
\hline
$T = (V, E)$ & Join tree with table nodes $V$ and join edges $E$ \\
\hline
$R_i$ & Relation/table at node $v_i \in V$ \\
\hline
$t$ & Tuple/entry in any table (may include metadata depending on processing phase) \\
\hline
$\localmult$ & Local multiplicity ($\alpha_{\text{local}}$): number of times a tuple appears in subtree join result \\
\hline
$\finalmult$ & Final multiplicity ($\alpha_{\text{final}}$): number of times a tuple appears in complete join result \\
\hline
$\foreignsum$ & Foreign cumulative sum: accumulated foreign contributions from parent multiplicities \\
\hline
% Entry Type Constants
$\typesource$ & SOURCE entry type constant ($\tau_{\text{src}}$) \\
\hline
$\typestart$ & TARGET\_START entry type constant ($\tau_{\text{start}}$) \\
\hline 
$\typeend$ & TARGET\_END entry type constant ($\tau_{\text{end}}$) \\
\hline
% Variables and Data Structures
$\entry$ & General entry variable \\
\hline
$e_s, e_t$ & Start and end entry variables \\
\hline
$\foreigncumsum$ & Foreign cumulative sum (temporary): intermediate values during dual-counter computation \\
\hline
$\localweight$ & Local weight counter ($w_{\text{local}}$) \\
\hline
$\localcumsum$ & Local cumulative sum (temporary): intermediate values during bottom-up computation \\
\hline
$\precedence$ & Entry type precedence mapping ($\pi$) \\
\hline
% Field Accessors
$e.\fieldtype$ & Entry type field (replaces .type) \\
\hline
$e.\fielddata$ & Entry data/tuple reference (replaces .data) \\
\hline
$t.\fieldindex$ & Original tuple index (replaces .orig\_idx) \\
\hline
$t.\joinattr$ & Join attribute ($a$) \\
\hline
$\Rcomb$ & \combinedtable\ of entries for dual-entry processing, sorted by join attribute \\
\hline
$(c_1, c_2)$ & Band join constraint parameters \\
\hline
\end{tabular}
\end{table}

\subsection{Formal Definitions of Multiplicities}

We define three key multiplicities that track tuple participation throughout the join computation:

\textbf{Local Multiplicity ($\localmult$):} For a tuple $t$ in table $\Rv$ at node $v$ in the join tree, the local multiplicity represents the number of times $t$ participates in the join result when considering only the visited portion of the subtree rooted at $v$. During the bottom-up phase, this is computed incrementally: after processing child $c_i$ of $v$, we have:
$$t.\localmult = |\{r \in \bowtie_{T_v^{(i)}} : t \in r\}|$$
where $T_v^{(i)}$ denotes the subtree rooted at $v$ restricted to $v$ itself and its first $i$ processed children (and their subtrees). After all children are processed, $T_v^{(k)} = T_v$ where $k = |children(v)|$. For leaf nodes, $\localmult = 1$ for all tuples.

\textbf{Final Multiplicity ($\finalmult$):} For any tuple $t$ in any table, the final multiplicity represents the number of times $t$ appears in the complete join result across all tables. Formally:
$$t.\finalmult = |\{r \in \bowtie_{T} : t \in r\}|$$
where $T$ is the entire join tree and $\bowtie_{T}$ represents the complete join result. For the root node, $\finalmult = \localmult$. For all other nodes, $\finalmult$ is computed during the top-down phase by propagating information from parent to children.

\textbf{Foreign Multiplicity ($\foreignmult$):} For a tuple $t$ in table $\Rv$ at node $v$ in the join tree, the foreign multiplicity represents the number of times $t$ participates in the join result when considering all tables \emph{outside} the subtree rooted at $v$, plus the node $v$ itself. Formally:
$$t.\foreignmult = |\{r \in \bowtie_{T \setminus T_v^{-}} : t \in r\}|$$
where $T_v^{-}$ denotes the subtree rooted at $v$ excluding $v$ itself, and $T \setminus T_v^{-}$ represents all tables in the tree except those in the children's subtrees. This counts how many times $t$ appears when joining with all tables not in its subtree. The key relationship $\finalmult = \localmult \times \foreignmult$ holds because we assume an acyclic join tree. Specifically, there are no join conditions connecting any node in $T_v^{-}$ to any node in $T \setminus T_v$ (all connections must go through $v$). This independence allows the multiplicities to multiply. In practice, we compute $\foreignmult = \frac{\finalmult}{\localmult}$ during the top-down phase.

\textbf{Foreign Multiplicity Sum ($\foreignsum$):} For a child tuple $t_c$ in table $\Rc$ with parent node $v$, if we were to join all tables in $T \setminus T_c^{-}$ and sort the result by the join attribute between $v$ and $c$, then $t_c.\foreignsum$ is the index of the first entry from the parent table that matches $t_c$. This value is computed during the top-down phase and is used in the align-concatenate phase to determine the correct positioning of tuples in the final result.

\subsection{Common Utilities Across Multiple Phases}

Our algorithm employs several oblivious operations that serve as common utilities across multiple phases.

\textbf{ObliviousSort} utility is the foundation of our approach, utilizing predetermined comparison networks~\cite{batcher1968} to sort tables with fixed access patterns that remain independent of actual data values. The sorting network's structure is determined solely by the input size, ensuring that the sequence of comparisons and swaps follows the same pattern regardless of the data being sorted, which is essential for maintaining oblivious properties in secure computation environments.

\textbf{LinearPass} utility represents our core primitive for processing sorted tables through stateless window operations. This utility applies functions to sliding windows of size 2 over sorted data, where each function operates exclusively on the current window content and position index without any external state dependencies. The function must access (read / write) fixed locations relative to the window, ensuring oblivious access patterns.

\begin{algorithm}[H]
\caption{LinearPass: Apply window function across table with sliding window size 2}
\label{alg:linear-pass}
\begin{algorithmic}[1]
\Function{LinearPass}{$R$, $WindowFunc$}
    \For{$i = 1$ \textbf{to} $|R| - 1$}
        \State $window \leftarrow R[i : i + 1]$ \Comment{Extract window of size 2}
        \State \Call{WindowFunc}{$window$, $i$} \Comment{Apply function to window}
    \EndFor
    \State \Return $R$ \Comment{Return modified table}
\EndFunction
\end{algorithmic}
\end{algorithm}

\textbf{Map} utility provides element-wise transformations across table entries, applying the same function to each row independently. The function reads the input row, and creates an output row with potentially different schema. This is used to change schema of table, adding or removing columns.

\begin{algorithm}[H]
\caption{Map: Apply transformation function to each row independently}
\label{alg:map}
\begin{algorithmic}[1]
\Function{Map}{$R$, $TransformFunc$}
    \State $R_{out} \leftarrow []$ \Comment{Initialize output table}
    \For{$i = 1$ \textbf{to} $|R|$}
        \State $R_{out}[i] \leftarrow$ \Call{TransformFunc}{$R[i]$, $i$}
    \EndFor
    \State \Return $R_{out}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\textbf{ParallelPass} utility processes two tables of same size in parallel by applying a window function to corresponding pairs of rows. The function modifies the rows in-place, similar to LinearPass but operating on aligned pairs from two tables rather than a sliding window.

\begin{algorithm}[H]
\caption{ParallelPass: Apply window function to aligned pairs from two tables}
\label{alg:parallel-pass}
\begin{algorithmic}[1]
\Function{ParallelPass}{$R_1$, $R_2$, $WindowFunc$}
    \Require $|R_1| = |R_2|$ \Comment{Tables must have same size}
    \For{$i = 1$ \textbf{to} $|R_1|$}
        \State $window \leftarrow [R_1[i], R_2[i]]$ \Comment{Create window from aligned pair}
        \State \Call{WindowFunc}{$window$, $i$} \Comment{Apply function to modify in-place}
    \EndFor
    \State \Return $(R_1, R_2)$ \Comment{Return modified tables}
\EndFunction
\end{algorithmic}
\end{algorithm}

\textbf{Additional Primitives:} Our algorithm also relies on two additional oblivious primitives:
\begin{itemize}
\item \textbf{ObliviousExpand:} This primitive from the \odbj\ framework~\cite{krastnikov2020} duplicates each tuple according to its multiplicity, creating an expanded table where each original tuple appears the specified number of times.
\item \textbf{HorizontalConcatenate:} This operation concatenates two tables horizontally, combining all columns from both tables while maintaining the same number of rows. Each row in the result contains the attributes from the corresponding rows in both input tables.
\end{itemize}

\textbf{Join Condition Encoding:} Any join condition between columns can be expressed as an interval constraint. Specifically, a condition between parent column $v.\joinattr$ and child column $c.\joinattr$ can be parsed as: $c.\joinattr \in v.\joinattr + [x, y]$, where the interval $[x, y]$ may use open or closed boundaries and $x, y \in \mathbb{R} \cup \{\pm\infty\}$.

Sample join predicates map to intervals as follows:
\begin{itemize}
\item Equality: $v.\joinattr = c.\joinattr$ maps to $c.\joinattr \in v.\joinattr + [0, 0]$
\item Inequality: $v.\joinattr > c.\joinattr$ maps to $c.\joinattr \in v.\joinattr + (-\infty, 0)$
\item Band constraint: $v.\joinattr \geq c.\joinattr - 1$ maps to $c.\joinattr \in v.\joinattr + [-1, \infty)$
\end{itemize}

When multiple conditions constrain the same join, we compute their interval intersection. For instance, combining $v.\joinattr > c.\joinattr$ (yielding $(-\infty, 0)$) with $v.\joinattr \leq c.\joinattr + 1$ (yielding $[-1, \infty)$) produces the final interval $[-1, 0)$.

The constraint function $\constraint(v,c)$ operationalizes this interval representation by mapping each parent-child relationship to boundary parameters $\constraintparam = ((\deviationone, \equalityone), (\deviationtwo, \equalitytwo))$. Here, $\deviationone$ and $\deviationtwo$ define the interval endpoints, while $\equalityone$ and $\equalitytwo$ specify whether boundaries are closed (EQ) or open (NEQ). This encoding is fundamental to the dual-entry technique used throughout the algorithm. For a target tuple with join attribute value $v$, the boundary parameters create: (i) a START entry at $v + \deviationone$ where if $\equalityone = \text{EQ}$, it includes values $\geq v + \deviationone$, and if $\equalityone = \text{NEQ}$, it includes values $> v + \deviationone$; and (ii) an END entry at $v + \deviationtwo$ where if $\equalitytwo = \text{EQ}$, it includes values $\leq v + \deviationtwo$, and if $\equalitytwo = \text{NEQ}$, it includes values $< v + \deviationtwo$. This encoding allows the dual-entry technique to handle arbitrary range predicates by converting them into boundary entries that can be processed obliviously.

\subsection{Algorithm Structure}

The algorithm begins with initialization to add metadata columns, then operates in four main phases:

\begin{enumerate}
\item \textbf{Initialization (Section~\ref{sec:initialization}):} Add metadata columns to create \augmentedtables
\item \textbf{Phase 1 - Bottom-Up (Section~\ref{sec:bottom-up}):} Compute local multiplicities ($\localmult$) using dual-entry technique for band constraints
\item \textbf{Phase 2 - Top-Down (Section~\ref{sec:top-down}):} Propagate final multiplicities ($\finalmult$) from root to leaves using foreign multiplicity computation
\item \textbf{Phase 3 - Distribution and Expansion (Section~\ref{sec:distribute-expand}):} Create \expandedtables\ by replicating each tuple according to its $\finalmult$ using oblivious distribution
\item \textbf{Phase 4 - Alignment and Concatenation (Section~\ref{sec:align-concat}):} Reorder \expandedtables\ using $\foreignsum$ for alignment, then concatenate to form the final join result
\end{enumerate}

Each phase maintains oblivious access patterns by using the primitives described above. The dual-entry technique transforms range-based band constraints into cumulative sum computations, enabling efficient oblivious processing of inequality joins.

\begin{algorithm}[H]
\caption{Main Algorithm Framework: Oblivious multi-way band join with initialization and four phases}
\label{alg:main}
\begin{algorithmic}[1]
\Function{ObliviousMultiWayBandJoin}{$T = (V, E)$}
    \State $T_{init} \leftarrow$ \Call{InitializeAllTables}{$T$} \Comment{Initialization: Add metadata columns}
    \State $T_{local} \leftarrow$ \Call{BottomUpPhase}{$T_{init}$} \Comment{Phase 1: Compute local multiplicities}
    \State $T_{final} \leftarrow$ \Call{TopDownPhase}{$T_{local}$} \Comment{Phase 2: Compute final multiplicities}
    \State $T_{expanded} \leftarrow$ \Call{DistributeExpand}{$T_{final}$} \Comment{Phase 3: Distribute and expand}
    \State $Result \leftarrow$ \Call{ConstructJoinResult}{$T_{expanded}$, $root$} \Comment{Phase 4: Construct join result}
    \State \Return $Result$ \Comment{Return final join result}
\EndFunction
\end{algorithmic}
\end{algorithm}

%----------------------------------------------------------------------
\section{Initialization}
\label{sec:initialization}
%----------------------------------------------------------------------

The initialization phase prepares the join tree for multiplicity computation by transforming \inputtables\ into \augmentedtables\ with empty metadata columns using the Map primitive. All metadata fields are initialized with null placeholders, and actual values are computed in the bottom-up and top-down phases.

\begin{algorithm}[H]
\caption{Initialize \augmentedtables: Add metadata columns $\{\fieldindex, \localmult, \finalmult, \foreignsum\}$ to input tables using Map primitive with null placeholders. $n_i = |R_i|$, $N = \sum_{i=1}^{k} n_i$.}
\label{alg:initialize}
\begin{algorithmic}[1]
\Function{InitializeAllTables}{$T$}
    \ForAll{nodes $v \in V$}
        \State $R_v \leftarrow$ \Call{Map}{$\Rv$, AddMetadataColumns}
        \State \Call{LinearPass}{$\Rv$, WindowSetOriginalIndex}
    \EndFor
    \State \Return $T$\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Add Metadata Columns: Map function to extend tuples with null metadata}
\label{alg:add-metadata}
\begin{algorithmic}[1]
\Function{AddMetadataColumns}{$t$, $index$}
    \State $t.\fieldindex \leftarrow 0$
    \State $t.\localmult \leftarrow null$
    \State $t.\finalmult \leftarrow null$
    \State $t.\foreignsum \leftarrow null$
    \State \Return $t$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Window Set Original Index: Assign sequential indices with sliding window size 2}
\label{alg:window-set-orig-index}
\begin{algorithmic}[1]
\Function{WindowSetOriginalIndex}{$window$}
    \State $window[1].\fieldindex \leftarrow window[0].\fieldindex + 1$
\EndFunction
\end{algorithmic}
\end{algorithm}

The initialization adds metadata columns using Map, then uses LinearPass to assign sequential original indices. This demonstrates the stateless window-based approach where each tuple's index is computed from its predecessor in the sliding window. 
%----------------------------------------------------------------------
\section{Phase 1: Bottom-Up Multiplicity Computation}
\label{sec:bottom-up}
%----------------------------------------------------------------------

The bottom-up phase computes local multiplicities ($\localmult$) by traversing the join tree $T$ in post-order, as shown in Algorithm~\ref{alg:bottom-up}. For leaf nodes, we initialize each tuple $t \in R_{leaf}$ with $t.\localmult = 1$. For non-leaf nodes, the algorithm processes each parent-child pair $(v, c)$ where $v$ is the parent and $c \in children(v)$. The key insight is that at any point during the traversal, for each visited node $v$, each tuple $t \in \Rv$ has $t.\localmult$ equal to the number of join results it participates in when considering only the portion of the subtree rooted at $v$ that has been visited so far. After all children of $v$ have been processed, $t.\localmult = |\{r \in \bowtie_{T_v^{visited}} : t \in r\}|$ where $T_v^{visited}$ represents the subtree rooted at $v$ restricted to nodes that have been visited in the post-order traversal.

For each parent-child pair $(v, c)$, the algorithm invokes \textsc{ComputeLocalMultiplicities} (Algorithm~\ref{alg:compute-local}) with tables $\Rv$ (target) and $\Rc$ (source), along with constraint parameters $\constraintparam = \constraint(v,c)$ that encode the join condition. This updates each tuple $t_v \in \Rv$ by computing ${t_v}.\localmult^{\text{new}} = {t_v}.\localmult^{\text{old}} \times \sum_{t_c \in \Rc : (t_v, t_c) \text{ satisfy } \constraint(v,c)} t_c.\localmult$, where the second term represents the sum of local multiplicities of all matching tuples from child $c$.

The core innovation lies in the dual-entry technique for handling band join constraints. The \textsc{CombineTable} function (Algorithm~\ref{alg:combine-table}) creates two boundary markers for each tuple in the target (parent) table---START and END entries---that mark where the matching range begins and ends. For example, if a parent tuple with value 10 matches child tuples between values 8 and 12, \textsc{CombineTable} creates a START entry at 8 and an END entry at 12, then combines these boundary entries with the source (child) tuples into a single table.

We then sort by \textsc{ComparatorJoinAttr} (Algorithm~\ref{alg:comparator-join-attr}), which orders entries primarily by join attribute value and secondarily by a precedence based on entry type and equality type. The precedence ordering (defined by \textsc{GetPrecedence} in Algorithm~\ref{alg:get-precedence}) ensures that (START, EQ) and (END, NEQ) entries come first with precedence 1, SOURCE entries have precedence 2, and (START, NEQ) and (END, EQ) entries come last with precedence 3. This careful ordering guarantees that for any target entry $\entry_{target}$ that derives boundary entries $\startentry$ and $\stopentry$, the set of source entries $\{\entry_{source}\}$ appearing between $\startentry$ and $\stopentry$ in the sorted order is exactly the set of source entries that satisfy the join condition with $\entry_{target}$.

We apply \textsc{WindowComputeLocalSum} (Algorithm~\ref{alg:window-compute-local-sum}) via a linear pass to maintain a running sum of local multiplicities: the sum increases by $\localmult$ when we encounter SOURCE entries, and the current sum gets recorded when we hit START/END boundaries. We then sort by \textsc{ComparatorPairwise} to place START and END pairs (which originated from the same target tuple) next to each other. Finally, we apply \textsc{WindowComputeLocalInterval} (Algorithm~\ref{alg:window-compute-local-interval}) via a linear pass to compute the difference between each pair's cumulative sums, yielding the local interval that represents the local multiplicity contribution from the child's subtree for that target tuple.

After creating and sorting the combined table, we apply \textsc{UpdateTargetMultiplicity} (Algorithm~\ref{alg:update-target-multiplicity}) via a parallel pass to propagate the computed intervals back to the parent table, multiplying each target tuple's existing local multiplicity by the contribution from this child (the interval value) to produce the updated local multiplicities.

\begin{algorithm}[H]
\caption{Bottom-Up Phase: Compute local multiplicities from leaves to root}
\label{alg:bottom-up}
\begin{algorithmic}[1]
\Function{BottomUpPhase}{$T$, $root$}
    \State $order \leftarrow$ \Call{PostOrderTraversal}{$T$, $root$}
    \ForAll{nodes $v$ in $order$}
        \If{$v$ is a leaf}
            \ForAll{tuple $t \in R_v$}
                \State $t.\localmult \leftarrow 1$
            \EndFor
        \Else
            \ForAll{child nodes $c$ of $v$}
                \State $R_v \leftarrow$ \Call{ComputeLocalMultiplicities}{$\Rv$, $\Rc$, $\constraint(v,c)$}
            \EndFor
        \EndIf
    \EndFor
    \State \Return $T$\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Post-Order Traversal: Visit children before parents in tree}
\label{alg:post-order}
\begin{algorithmic}[1]
\Function{PostOrderTraversal}{$T$, $root$}
    \State $order \leftarrow$ empty list
    \ForAll{child nodes $c$ of $root$}
        \State $order \leftarrow order + $ \Call{PostOrderTraversal}{$T$, $c$}
    \EndFor
    \State Append $root$ to $order$
    \State \Return $order$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Compute Local Multiplicities: Compute new local multiplicities for parent node in bottom-up phase}
\label{alg:compute-local}
\begin{algorithmic}[1]
\Function{ComputeLocalMultiplicities}{$\Rtarget$, $\Rsource$, $\constraintparam$}
    \State $\Rcomb \leftarrow$ \Call{CombineTable}{$\Rtarget$, $\Rsource$, $\constraintparam$}
    \State $\Rcomb \leftarrow$ \Call{Map}{$\Rcomb$, $\lambda e: (e.\localsum \leftarrow e.\localmult, e.\localinterval \leftarrow 0, e)$}
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorJoinAttr}
    \State \Call{LinearPass}{$\Rcomb$, WindowComputeLocalSum}
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorPairwise}
    \State \Call{LinearPass}{$\Rcomb$, WindowComputeLocalInterval}
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorEndFirst}
    \State $\Rtruncated \leftarrow \Rcomb[1:|\Rtarget|]$
    \State \Call{ParallelPass}{$\Rtruncated$, $\Rtarget$, UpdateTargetMultiplicity}
    \State \Return $\Rtarget$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Combine Table: Create start/end boundary entries for each target tuple and merge with source entries}
\label{alg:combine-table}
\begin{algorithmic}[1]
\Function{CombineTable}{$\Rtarget$, $\Rsource$, $\constraintparam$}
    \State $((\deviationone, \equalityone), (\deviationtwo, \equalitytwo)) \leftarrow \constraintparam$
    \State $R_{source}' \leftarrow$ \Call{Map}{$\Rsource$, \textbf{function}($t$):}
    \State \quad $e.\fieldtype \leftarrow \typesource$
    \State \quad $e.\fieldequalitytype \leftarrow null$
    \State \quad $e.\joinattr \leftarrow t.\joinattr$
    \State \quad $e.\fieldindex \leftarrow t.\fieldindex$
    \State \quad $e.\localmult \leftarrow t.\localmult$
    \State \quad $e.\finalmult \leftarrow t.\finalmult$
    \State \quad $e.\foreignsum \leftarrow t.\foreignsum$
    \State \quad \Return $e$
    \State $R_{begin}' \leftarrow$ \Call{Map}{$\Rtarget$, \textbf{function}($t$):}
    \State \quad $e.\fieldtype \leftarrow \typestart$
    \State \quad $e.\fieldequalitytype \leftarrow \equalityone$
    \State \quad $e.\joinattr \leftarrow t.\joinattr + \deviationone$
    \State \quad $e.\fieldindex \leftarrow t.\fieldindex$
    \State \quad $e.\localmult \leftarrow t.\localmult$
    \State \quad $e.\finalmult \leftarrow t.\finalmult$
    \State \quad $e.\foreignsum \leftarrow t.\foreignsum$
    \State \quad \Return $e$
    \State $R_{end}' \leftarrow$ \Call{Map}{$\Rtarget$, \textbf{function}($t$):}
    \State \quad $e.\fieldtype \leftarrow \typeend$
    \State \quad $e.\fieldequalitytype \leftarrow \equalitytwo$
    \State \quad $e.\joinattr \leftarrow t.\joinattr + \deviationtwo$
    \State \quad $e.\fieldindex \leftarrow t.\fieldindex$
    \State \quad $e.\localmult \leftarrow t.\localmult$
    \State \quad $e.\finalmult \leftarrow t.\finalmult$
    \State \quad $e.\foreignsum \leftarrow t.\foreignsum$
    \State \quad \Return $e$
    \State $\Rcomb \leftarrow R_{source}' + R_{begin}' + R_{end}'$
    \State \Return $\Rcomb$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Comparator Join Attribute: Sort entries by join attribute, then by entry type precedence\\
\small\textit{Precedence: (START, EQ) → 1, (END, NEQ) → 1, (SOURCE, null) → 2, (START, NEQ) → 3, (END, EQ) → 3}}
\label{alg:comparator-join-attr}
\begin{algorithmic}[1]
\Function{ComparatorJoinAttr}{$e_1$, $e_2$}
    \If{$e_1.\joinattr < e_2.\joinattr$}
        \Return -1
    \ElsIf{$e_1.\joinattr > e_2.\joinattr$}
        \Return 1
    \Else
        \State $p_1 \leftarrow$ \Call{GetPrecedence}{$(e_1.\fieldtype, e_1.\fieldequalitytype)$}
        \State $p_2 \leftarrow$ \Call{GetPrecedence}{$(e_2.\fieldtype, e_2.\fieldequalitytype)$}
        \If{$p_1 < p_2$}
            \Return -1
        \ElsIf{$p_1 > p_2$}
            \Return 1
        \Else
            \Return 0
        \EndIf
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Window Compute Local Sum: Compute cumulative sum with sliding window size 2}
\label{alg:window-compute-local-sum}
\begin{algorithmic}[1]
\Function{WindowComputeLocalSum}{$window$}
    \If{$window[1].\fieldtype = \typesource$}
        \State $window[1].\localsum \leftarrow window[0].\localsum + window[1].\localmult$
    \Else  \Comment{$window[1].\fieldtype \in \{\typestart, \typeend\}$}
        \State $window[1].\localsum \leftarrow window[0].\localsum$
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Comparator Pairwise: Organize entries for pairwise START/END processing by grouping targets first, then by index}
\label{alg:comparator-pairwise}
\begin{algorithmic}[1]
\Function{ComparatorPairwise}{$e_1$, $e_2$}
    \Comment{First: Target entries (START/END) before SOURCE entries}
    \If{$e_1.\fieldtype \in \{\typestart, \typeend\}$ and $e_2.\fieldtype = \typesource$}
        \Return -1
    \ElsIf{$e_1.\fieldtype = \typesource$ and $e_2.\fieldtype \in \{\typestart, \typeend\}$}
        \Return 1
    \EndIf
    \Comment{Second: Sort by original index}
    \If{$e_1.\fieldindex < e_2.\fieldindex$}
        \Return -1
    \ElsIf{$e_1.\fieldindex > e_2.\fieldindex$}
        \Return 1
    \EndIf
    \Comment{Third: START before END for same index}
    \If{$e_1.\fieldtype = \typestart$ and $e_2.\fieldtype = \typeend$}
        \Return -1
    \ElsIf{$e_1.\fieldtype = \typeend$ and $e_2.\fieldtype = \typestart$}
        \Return 1
    \Else
        \Return 0
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Window Compute Local Interval: Compute range difference between start/end entries with window size 2}
\label{alg:window-compute-local-interval}
\begin{algorithmic}[1]
\Function{WindowComputeLocalInterval}{$window$}
    \If{$window[0].\fieldtype = \typestart$ and $window[1].\fieldtype = \typeend$}
        \State $window[1].\localinterval \leftarrow window[1].\localsum - window[0].\localsum$
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Comparator End First: Put END entries first, then sort by original index}
\label{alg:comparator-end-first}
\begin{algorithmic}[1]
\Function{ComparatorEndFirst}{$e_1$, $e_2$}
    \Comment{First: END entries before all others}
    \If{$e_1.\fieldtype = \typeend$ and $e_2.\fieldtype \neq \typeend$}
        \Return -1
    \ElsIf{$e_1.\fieldtype \neq \typeend$ and $e_2.\fieldtype = \typeend$}
        \Return 1
    \EndIf
    \Comment{Second: Sort by original index}
    \If{$e_1.\fieldindex < e_2.\fieldindex$}
        \Return -1
    \ElsIf{$e_1.\fieldindex > e_2.\fieldindex$}
        \Return 1
    \Else
        \Return 0
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Update Target Multiplicity: Multiply target's local multiplicity by computed interval}
\label{alg:update-target-multiplicity}
\begin{algorithmic}[1]
\Function{UpdateTargetMultiplicity}{$e_{combined}$, $e_{target}$}
    \State $e_{target}.\localmult \leftarrow e_{target}.\localmult \times e_{combined}.\localinterval$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Get Entry Type Precedence: Map (entry\_type, equality\_type) tuple to precedence value}
\label{alg:get-precedence}
\begin{algorithmic}[1]
\Function{GetPrecedence}{$(entry\_type, equality\_type)$}
    \If{$(entry\_type, equality\_type) = (\typestart, \equalityequal)$}
        \Return 1
    \ElsIf{$(entry\_type, equality\_type) = (\typeend, \equalitynonequal)$}
        \Return 1
    \ElsIf{$(entry\_type, equality\_type) = (\typesource, null)$}
        \Return 2
    \ElsIf{$(entry\_type, equality\_type) = (\typestart, \equalitynonequal)$}
        \Return 3
    \ElsIf{$(entry\_type, equality\_type) = (\typeend, \equalityequal)$}
        \Return 3
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}




%----------------------------------------------------------------------
\section{Phase 2: Top-Down Final Multiplicity Propagation}
\label{sec:top-down}
%----------------------------------------------------------------------

The top-down phase propagates final multiplicities ($\finalmult$) from the root to all nodes in the tree, mirroring the reconstruction phase of Yannakakis~\cite{yannakakis1981}. This phase computes how many times each tuple appears in the complete join result by considering contributions from outside its subtree. The traversal proceeds in pre-order, starting from the root where $\finalmult = \localmult$ (since the root has no ancestors), then propagating downward to compute each child's final multiplicity based on its parent's values.

For each parent-child pair $(v, c)$ during the pre-order traversal, the algorithm invokes \textsc{PropagateFinalMultiplicities} (Algorithm~\ref{alg:propagate-final}) to compute the final multiplicities for child table $\Rc$. The key insight is that each child tuple's final multiplicity equals its local multiplicity times its foreign multiplicity, where the foreign multiplicity ($\foreignmult$) represents the number of join results from tables outside the child's subtree that connect through the parent. This is computed as: $t_c.\finalmult = t_c.\localmult \times t_c.\foreignmult$.

The core question in the top-down phase is: what would be the multiplicity of each parent tuple if we excluded the child table and its entire subtree? That is, what is the multiplicity of parent (source) table entries in the join result of $\mathcal{T} \setminus \mathcal{T}_c$? Since the final multiplicity is the product of contributions from all neighbors, we can recover this by division. We use a running sum called "local weight" to track the sum of matching child tuples' local multiplicities---this represents the child subtree's contribution. By dividing a parent tuple's final multiplicity by this local weight, we recover its multiplicity in $\mathcal{T} \setminus \mathcal{T}_c$. The sum of these multiplicities for all matching parent tuples gives us the foreign multiplicity ($\foreignmult$), which represents the contribution from $\mathcal{T} \setminus \mathcal{T}_c$ and complements the local multiplicity (contribution from $\mathcal{T}_c$).

To compute these values obliviously, we employ a similar structure as the bottom-up phase. We use \textsc{CombineTable} to create START and END boundaries for target table tuples, while SOURCE entries represent source table tuples. The difference from bottom-up is that here the child table is the target (receiving multiplicities) and the parent table is the source (providing multiplicities). After sorting by \textsc{ComparatorJoinAttr} (Algorithm~\ref{alg:comparator-join-attr}), we apply \textsc{WindowComputeForeignSum} (Algorithm~\ref{alg:window-compute-foreign-sum}) via a linear pass that simultaneously tracks two counters. When we encounter START/END boundaries, we update the local weight by adding or subtracting the child tuple's local multiplicity. When we encounter SOURCE entries (parent tuples), we increment the foreign cumulative sum by the parent's final multiplicity divided by the current local weight. This division recovers the parent's multiplicity in $\mathcal{T} \setminus \mathcal{T}_c$, and the accumulation gives each child tuple its foreign multiplicity sum ($\foreignsum$). This $\foreignsum$ serves dual purposes: it provides the foreign multiplicity for computing $\finalmult = \localmult \times \foreignmult$, and later serves as the alignment key during result construction.

After processing all parent-child pairs in pre-order, every tuple in every table has its final multiplicity computed, representing exactly how many times it will appear in the complete join result. This prepares the tables for the distribution and expansion phase where tuples are replicated according to their final multiplicities.

\begin{algorithm}[H]
\caption{Top-Down Phase: Propagate final multiplicities from root to leaves}
\label{alg:top-down}
\begin{algorithmic}[1]
\Function{TopDownPhase}{$T$, $root$}
    \ForAll{tuple $t \in R_{root}$}
        \State $t.\finalmult \leftarrow t.\localmult$ \Comment{Root final = local}
    \EndFor
    \ForAll{nodes $v$ in pre-order traversal of $T$ from $root$}
        \ForAll{child nodes $c$ of $v$}
            \State $R_c \leftarrow$ \Call{PropagateFinalMultiplicities}{$\Rv$, $\Rc$, $\constraint(v,c)$}
        \EndFor
    \EndFor
    \State \Return $T$ \Comment{Return tree with tables containing computed final multiplicities}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Propagate Final Multiplicities: Distribute parent multiplicities to children using dual counters}
\label{alg:propagate-final}
\begin{algorithmic}[1]
\Function{PropagateFinalMultiplicities}{$\Rsource$, $\Rtarget$, $\constraintparam$}
    \State $\Rcomb \leftarrow$ \Call{CombineTable}{$\Rtarget$, $\Rsource$, $\constraintparam$}
    \State $\Rcomb \leftarrow$ \Call{Map}{$\Rcomb$, $\lambda e:$}
    \State \quad $(e.\localweight \leftarrow e.\localmult,$
    \State \quad $\phantom{(}e.\foreigncumsum \leftarrow 0,$
    \State \quad $\phantom{(}e.\foreigninterval \leftarrow 0, e)$
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorJoinAttr}
    \State \Call{LinearPass}{$\Rcomb$, WindowComputeForeignSum}
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorPairwise}  
    \State \Call{LinearPass}{$\Rcomb$, WindowComputeForeignInterval}
    \State \Call{ObliviousSort}{$\Rcomb$, ComparatorEndFirst}
    \State $\Rtruncated \leftarrow \Rcomb[1:|\Rtarget|]$
    \State \Call{ParallelPass}{$\Rtruncated$, $\Rtarget$, UpdateTargetFinalMultiplicity}
    \State \Return $\Rtarget$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Window Compute Foreign Sum: Track foreign and local weight counters simultaneously}
\label{alg:window-compute-foreign-sum}
\begin{algorithmic}[1]
\Function{WindowComputeForeignSum}{$window$}
    \If{$window[1].\fieldtype = \typestart$}
        \State $window[1].\localweight \leftarrow window[0].\localweight + window[1].\localmult$
        \State $window[1].\foreigncumsum \leftarrow window[0].\foreigncumsum$
    \ElsIf{$window[1].\fieldtype = \typeend$}
        \State $window[1].\localweight \leftarrow window[0].\localweight - window[1].\localmult$
        \State $window[1].\foreigncumsum \leftarrow window[0].\foreigncumsum$
    \ElsIf{$window[1].\fieldtype = \typesource$}
        \State $window[1].\localweight \leftarrow window[0].\localweight$
        \State $window[1].\foreigncumsum \leftarrow window[0].\foreigncumsum + window[1].\finalmult / window[1].\localweight$
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Window Compute Foreign Interval: Compute foreign multiplicity from START/END cumulative sums}
\label{alg:window-compute-foreign-interval}
\begin{algorithmic}[1]
\Function{WindowComputeForeignInterval}{$window$}
    \If{$window[0].\fieldtype = \typestart$ and $window[1].\fieldtype = \typeend$}
        \State $\foreigninterval \leftarrow window[1].\foreigncumsum - window[0].\foreigncumsum$
        \State $window[1].\foreigninterval \leftarrow \foreigninterval$
        \State $window[1].\foreignsum \leftarrow window[0].\foreigncumsum$ \Comment{Record alignment position}
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Update Target Final Multiplicity: Propagate foreign intervals to compute final multiplicities}
\label{alg:update-target-final}
\begin{algorithmic}[1]
\Function{UpdateTargetFinalMultiplicity}{$e$, $t$}
    \State $t.\finalmult \leftarrow e.\foreigninterval \times t.\localmult$
    \State $t.\foreignsum \leftarrow e.\foreignsum$ \Comment{For alignment}
\EndFunction
\end{algorithmic}
\end{algorithm}

%----------------------------------------------------------------------
\section{Phase 3: Distribution and Expansion}
\label{sec:distribute-expand}
%----------------------------------------------------------------------

Each tuple must be replicated according to its final multiplicity $\finalmult$. We use the oblivious distribute-and-expand technique from \odbj~\cite{krastnikov2020}, which creates exactly $\finalmult$ copies of each tuple while maintaining oblivious access patterns. This technique first distributes tuples to their target positions, then expands them to fill the required space. The key property is that the expansion is data-oblivious: the access pattern depends only on the multiplicities, not on the actual data values.

%----------------------------------------------------------------------
\section{Phase 4: Alignment and Concatenation}
\label{sec:align-concat}
%----------------------------------------------------------------------

After expansion, tables must be aligned so that matching tuples appear in the same rows. The parent table is sorted by join attributes (and secondarily by other attributes), creating groups of identical tuples. Each group represents a distinct combination from the parent table that will be matched with corresponding child tuples.

The child table alignment uses the formula $\foreignsum + (\copyindex \div \localmult)$, where:
\begin{itemize}
\item $\foreignsum$ is the index of the first parent group that matches this child tuple
\item $\copyindex$ is the index of this copy among all copies of the same original tuple (0 to $\finalmult-1$)
\item $\localmult$ is the child tuple's local multiplicity
\end{itemize}

This formula ensures that every $\localmult$ copies of a child tuple increment to the next parent group, correctly distributing child copies across matching parent groups. After sorting by this alignment key, corresponding rows from parent and child tables are horizontally concatenated to form the partial join result. This process continues recursively through the join tree until all tables are combined.

\begin{algorithm}[H]
\caption{Result Construction}
\label{alg:result-construction}
\begin{algorithmic}[1]
\Function{ConstructJoinResult}{$T$, $root$}
    \State $result \leftarrow$ \Call{ObliviousExpand}{$R_{root}$} \Comment{Expand root table}
    \ForAll{nodes $v$ in pre-order traversal of $T$ from $root$}
        \ForAll{child nodes $c$ of $v$}
            \State $R_c^{expanded} \leftarrow$ \Call{ObliviousExpand}{$\Rc$} \Comment{Expand child table}
            \State $result \leftarrow$ \Call{AlignAndConcatenate}{$result$, $R_c^{expanded}$}
        \EndFor
    \EndFor
    \Return $result$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Align and Concatenate}
\label{alg:align-concatenate}
\begin{algorithmic}[1]
\Function{AlignAndConcatenate}{$R_{accumulator}$, $R_{child}$}
    \State \Call{ObliviousSort}{$R_{accumulator}$, JoinThenOtherAttributes} \Comment{Sort by join attrs, then others}
    \State \Call{LinearPass}{$R_{child}$, ComputeAlignmentKey} \Comment{Set alignment key for each tuple}
    \State \Call{ObliviousSort}{$R_{child}$, AlignmentKeyComparator}
    \State \Return \Call{HorizontalConcatenate}{$R_{accumulator}$, $R_{child}$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Compute Alignment Key}
\label{alg:compute-alignment}
\begin{algorithmic}[1]
\Function{ComputeAlignmentKey}{$tuple$}
    \State $tuple.\alignmentkey \leftarrow tuple.\foreignsum + (tuple.\copyindex \div tuple.\localmult)$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Join Then Other Attributes Comparator}
\label{alg:join-then-other-comparator}
\begin{algorithmic}[1]
\Function{JoinThenOtherAttributes}{$t_1$, $t_2$}
    \If{$t_1.\joinattr < t_2.\joinattr$}
        \Return -1
    \ElsIf{$t_1.\joinattr > t_2.\joinattr$}
        \Return 1
    \Else
        \Comment{Compare all other attributes}
        \Return \Call{CompareOtherAttr}{$t_1$, $t_2$}
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Alignment Key Comparator}
\label{alg:alignment-comparator}
\begin{algorithmic}[1]
\Function{AlignmentKeyComparator}{$t_1$, $t_2$}
    \If{$t_1.\alignmentkey < t_2.\alignmentkey$}
        \Return -1
    \ElsIf{$t_1.\alignmentkey > t_2.\alignmentkey$}
        \Return 1
    \Else
        \Return 0
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}