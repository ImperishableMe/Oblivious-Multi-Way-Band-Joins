\documentclass[sigconf]{acmart}

% Packages
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}  % from algorithmicx package
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{listings}
\usepackage{subcaption}

% Custom commands
\newcommand{\system}{NebulaDB\xspace}
\newcommand{\onehop}{ForwardFill\xspace}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\etal}{et al.\xspace}

% Remove ACM copyright for draft
\setcopyright{none}
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}

\begin{document}

\title{\system: Oblivious Property Graph Database}

\author{Author Names}
\affiliation{
  \institution{Institution}
  \city{City}
  \country{Country}
}
\email{email@institution.edu}

\begin{abstract}
Oblivious graph query processing is expensive due to multi-hop traversals requiring costly oblivious join operations.
Existing oblivious database techniques treat graph queries as generic relational joins, missing optimization opportunities inherent in graph structure.
We observe that graph traversals follow predictable node$\rightarrow$edge$\rightarrow$node patterns where the output size is bounded by the edge table---a quantity already public in standard threat models.
We present \system, an oblivious property graph database that exploits this insight through two contributions: (1) \onehop, an oblivious one-hop operator that uses duplicate suppression to achieve data-independent access patterns with public-sized output, and (2) a query decomposition framework that rewrites multi-hop queries to maximize \onehop usage.
Our evaluation on financial transaction workloads shows 1.2--1.9$\times$ speedup over non-decomposed oblivious execution while maintaining identical security guarantees.
\end{abstract}

\maketitle

%==============================================================================
\section{Introduction}
\label{sec:intro}
%==============================================================================

Property graph databases have become the foundation for modeling complex relationships in domains ranging from financial transaction networks and social platforms to biomedical knowledge graphs and fraud detection systems. As organizations increasingly deploy these systems in cloud environments, a critical security challenge emerges: how can we process graph queries without revealing sensitive information through observable memory access patterns? Traditional encryption protects data at rest, but an adversary with access to the execution environment---such as a compromised cloud hypervisor---can infer sensitive information by monitoring \emph{which} memory locations are accessed during query processing, even without seeing the actual data values. This class of side-channel attacks has motivated the development of \emph{oblivious} algorithms, where the sequence of memory accesses is independent of the input data. The challenge we address in this paper is: \textbf{how can we efficiently execute multi-hop graph queries while maintaining oblivious access patterns?}

The importance of this problem stems from both the prevalence of graph workloads and the severity of access pattern leakage. Graph queries inherently involve traversing relationships---finding accounts connected through transactions, identifying influence paths in social networks, or discovering drug-gene interactions in biomedical graphs. These multi-hop traversals touch data in patterns that directly reflect the underlying graph structure. Prior work has demonstrated that access patterns can reveal query predicates, join selectivities, and even reconstruct significant portions of the underlying data~\cite{TODO}. For regulated industries handling financial or healthcare data, such leakage may violate compliance requirements even when the data itself remains encrypted. Trusted Execution Environments (TEEs) like Intel TDX and SGX provide hardware-level isolation, but they do not hide memory access patterns from a privileged adversary---oblivious algorithms remain necessary within these secure enclaves.

Achieving oblivious graph query processing is fundamentally difficult because naive approaches fail in subtle ways. Consider a simple one-hop traversal: given a set of source accounts, find all transactions and their destination accounts. A standard hash join would build a hash table on source accounts and probe it for each edge. However, the \emph{number of probes per source node} reveals node degrees---a high-degree node causes more hash table accesses than a low-degree node. Even with encrypted data, an adversary observing cache lines can distinguish between nodes with 10 versus 1,000 outgoing edges. Padding all nodes to the maximum degree is prohibitively expensive and leaks the maximum degree itself. More sophisticated approaches using Oblivious RAM (ORAM) hide individual accesses but introduce logarithmic overhead per operation, making multi-hop queries impractical at scale. The core difficulty is that graph structure is \emph{inherently} reflected in access patterns---hiding it requires fundamentally rethinking how we process graph queries.

Prior work on oblivious query processing has largely treated graph queries as a special case of relational joins. Oblivious join algorithms~\cite{TODO} can compute multi-way joins while hiding intermediate result sizes, providing strong security guarantees for acyclic query patterns. However, these approaches treat all input tables uniformly---they do not exploit the specific structure of graph traversals where nodes and edges have a predictable relationship. A three-way join between source nodes, edges, and destination nodes is processed identically to any other three-table join, missing opportunities for optimization. On the other hand, work on oblivious graph \emph{analytics}---algorithms for PageRank, shortest paths, or connected components---focuses on iterative computations rather than the selective, predicate-driven queries typical of graph databases. There exists a gap: no prior system provides graph-native optimizations for oblivious query processing.

Our key insight is that \textbf{a single-hop graph traversal produces output bounded by the edge table size}---a quantity that is already public in our threat model. This observation enables a fundamentally more efficient approach. We introduce \textbf{\onehop}, an oblivious one-hop operator that joins source nodes, edges, and destination nodes using a novel \emph{duplicate suppression} technique: rather than probing the hash table once per edge (which leaks degree), we probe once per \emph{unique} node ID and propagate the result to all edges sharing that ID. This yields uniform access patterns regardless of degree distribution. Building on \onehop, we develop a \textbf{query decomposition} framework that rewrites multi-hop graph queries to maximize the use of one-hop operators, falling back to general oblivious multi-way joins only where necessary. The decomposed query executes significantly faster while providing identical security guarantees---all intermediate results either have public sizes (from \onehop) or are hidden by the multi-way join algorithm. Our evaluation on banking transaction workloads shows 1.2--1.9$\times$ speedup over non-decomposed oblivious execution for chain and branch query patterns.

\paragraph{Summary of Contributions.} This paper makes the following contributions:

\begin{itemize}
    \item \textbf{\onehop: An Oblivious One-Hop Operator (Section~\ref{sec:onehop}).} We present a novel algorithm for oblivious single-hop graph traversal. \onehop uses duplicate suppression and forward-filling to achieve uniform memory access patterns independent of node degree distribution, with output size equal to the edge table size.

    \item \textbf{Graph-Aware Query Decomposition (Section~\ref{sec:decomposition}).} We introduce a query rewriting framework that identifies one-hop patterns within multi-hop queries and decomposes them to maximize \onehop usage. The decomposition produces a reduced query suitable for existing oblivious multi-way join algorithms.

    \item \textbf{Security Analysis (Section~\ref{sec:security}).} We provide an informal security argument showing that our hybrid approach (\onehop + multi-way joins) leaks no more information than what is already public: base table sizes, query structure, and final output size.

    \item \textbf{Experimental Evaluation (Section~\ref{sec:evaluation}).} We evaluate \system on banking transaction queries, demonstrating 1.2--1.9$\times$ speedup over baseline oblivious execution while maintaining identical security properties.
\end{itemize}


%==============================================================================
\section{Background and Problem Definition}
\label{sec:background}
%==============================================================================

This section introduces the property graph model, defines our threat model, summarizes the prior work on oblivious multi-way joins that we build upon, and formally states the problem we address.

%------------------------------------------------------------------------------
\subsection{Property Graph Model}
\label{sec:background:graph}
%------------------------------------------------------------------------------

A \emph{property graph} $G = (V, E, L, P)$ consists of a set of nodes $V$, a set of directed edges $E \subseteq V \times V$, a labeling function $L$ that assigns labels to nodes and edges, and a property function $P$ that assigns key-value pairs to nodes and edges. Nodes represent entities (\eg accounts, users, products), while edges represent relationships between entities (\eg transactions, friendships, purchases). Both nodes and edges can carry properties---arbitrary key-value attributes such as \texttt{balance: 5000} for an account node or \texttt{amount: 150} for a transaction edge.

\paragraph{Storage Model.} Following standard practice in graph databases, we store property graphs using separate tables for each node label and edge label. A node table $N$ contains one row per node of that label, with columns for the node identifier and its properties. An edge table $E$ contains one row per edge, with columns for source node ID, destination node ID, and edge properties. For example, a financial graph might have an \texttt{Account} node table with columns \texttt{(id, owner, balance)} and a \texttt{Transaction} edge table with columns \texttt{(src\_id, dst\_id, amount, timestamp)}.

\paragraph{Graph Queries.} We focus on \emph{pattern matching} queries expressed in languages like Cypher or SPARQL. A query specifies a pattern of nodes and edges to match in the graph, optionally with predicates filtering on properties. We define query complexity in terms of \emph{hops}:

\begin{itemize}
    \item A \textbf{one-hop query} matches a single edge pattern: (source node) $\rightarrow$ [edge] $\rightarrow$ (destination node). For example, ``find all transactions from accounts with balance $>$ 10000'' matches the pattern:
    \begin{center}
    \texttt{(a:Account)-[t:Transaction]$\rightarrow$(b:Account)}\\
    \texttt{WHERE a.balance > 10000}
    \end{center}

    \item A \textbf{$k$-hop query} chains $k$ edge patterns, traversing $k$ relationships. For example, a 3-hop query might find ``accounts reachable within 3 transactions from a flagged account'':
    \begin{center}
    \small\texttt{(a1:Account)-[t1]$\rightarrow$(a2:Account)-[t2]$\rightarrow$}\\
    \small\texttt{(a3:Account)-[t3]$\rightarrow$(a4:Account)}
    \end{center}
\end{itemize}

In relational terms, a $k$-hop query corresponds to a $(2k+1)$-way join: $k+1$ node tables and $k$ edge tables, joined on foreign key relationships. The output contains tuples of matched nodes and edges satisfying the pattern and all predicates.

%------------------------------------------------------------------------------
\subsection{Threat Model}
\label{sec:background:threat}
%------------------------------------------------------------------------------

We consider a cloud deployment scenario where the graph database executes within a Trusted Execution Environment (TEE) such as Intel TDX or SGX. The TEE provides hardware-enforced isolation: code and data inside the TEE are protected from the host operating system, hypervisor, and other software. However, TEEs do not hide \emph{memory access patterns}---the sequence of memory addresses accessed during execution is observable by a privileged adversary.

\paragraph{Adversary Model.} We assume a semi-honest (honest-but-curious) adversary who:
\begin{itemize}
    \item Controls the cloud infrastructure outside the TEE (OS, hypervisor, firmware)
    \item Can observe memory access patterns at cache-line granularity
    \item Can monitor timing of memory accesses
    \item Cannot tamper with TEE execution or forge attestations
    \item Cannot access plaintext data inside the TEE
\end{itemize}

This adversary model captures realistic threats including compromised cloud administrators, malicious co-tenants exploiting side channels, and nation-state actors with physical access to hardware.

\paragraph{Information Leakage.} We distinguish between \emph{public} and \emph{secret} information:

\emph{Public information} (acceptable to reveal):
\begin{itemize}
    \item \textbf{Schema}: Node labels, edge labels, property names and types
    \item \textbf{Base table sizes}: Number of rows in each node and edge table ($|$\texttt{Account}$|$, $|$\texttt{Transaction}$|$, etc.)
    \item \textbf{Query structure}: The pattern being matched (\eg 3-hop chain query)
    \item \textbf{Final output size}: Number of result tuples returned to the client
\end{itemize}

\emph{Secret information} (must be hidden):
\begin{itemize}
    \item \textbf{Data values}: Actual property values (account balances, transaction amounts)
    \item \textbf{Intermediate result sizes}: Cardinality of partial query results during execution
    \item \textbf{Access patterns}: Which specific rows are accessed during query processing
    \item \textbf{Selectivity}: What fraction of rows satisfy query predicates
\end{itemize}

\begin{definition}[Oblivious Algorithm]
An algorithm $\mathcal{A}$ is \emph{oblivious} if for any two inputs $x$ and $y$ of the same size, the memory access sequences $\mathcal{A}(x)$ and $\mathcal{A}(y)$ are identically distributed. Informally, an observer cannot distinguish which input was processed by watching memory accesses.
\end{definition}

%------------------------------------------------------------------------------
\subsection{Oblivious Multi-Way Joins (Prior Work)}
\label{sec:background:joins}
%------------------------------------------------------------------------------

Our work builds upon prior research on oblivious multi-way join algorithms~\cite{TODO}, which we briefly summarize here. Given $k$ relations $R_1, \ldots, R_k$ with join predicates forming an acyclic join graph, an oblivious multi-way join computes $R_1 \bowtie R_2 \bowtie \cdots \bowtie R_k$ while hiding intermediate result sizes.

The key insight of prior work is that for acyclic queries, the join can be computed in two phases without materializing intermediate results:

\begin{enumerate}
    \item \textbf{Bottom-up phase}: Traverse the join tree from leaves to root, computing for each tuple how many times it will appear in the final result (its \emph{multiplicity}).

    \item \textbf{Top-down phase}: Traverse from root to leaves, replicating each tuple according to its multiplicity and aligning tuples that should appear together in the output.
\end{enumerate}

Both phases use oblivious primitives---oblivious sorting, oblivious compaction---to ensure access patterns are data-independent. The algorithm achieves $O(N \log N + \textit{OUT})$ time complexity where $N$ is the total input size and $\textit{OUT}$ is the output size.

\paragraph{Limitation for Graph Queries.} While oblivious multi-way joins provide strong security guarantees, they treat all input tables uniformly. A one-hop graph query (source nodes $\bowtie$ edges $\bowtie$ destination nodes) is processed identically to any other three-way join, requiring the full multi-way join machinery. This misses a key optimization opportunity: in graph queries, the edge table structurally connects the two node tables, and \emph{the output size is bounded by the edge table size} regardless of selectivity on node predicates.

%------------------------------------------------------------------------------
\subsection{Problem Statement}
\label{sec:background:problem}
%------------------------------------------------------------------------------

We now formally state the problem addressed in this paper.

\paragraph{Input:}
\begin{itemize}
    \item A property graph $G$ stored as node tables $N_1, \ldots, N_m$ and edge tables $E_1, \ldots, E_l$
    \item A $k$-hop pattern matching query $Q$ with optional predicates on nodes and edges
\end{itemize}

\paragraph{Output:}
\begin{itemize}
    \item All tuples $(n_1, e_1, n_2, e_2, \ldots, n_{k+1})$ matching the pattern $Q$
\end{itemize}

\paragraph{Requirements:}
\begin{enumerate}
    \item \textbf{Correctness}: The output must be identical to non-oblivious execution
    \item \textbf{Obliviousness}: Memory access patterns must be independent of data values
    \item \textbf{Efficiency}: Minimize the number of expensive oblivious operations (sorts, compactions)
\end{enumerate}

\paragraph{Goal:} Design an oblivious query execution strategy that exploits graph structure to reduce cost compared to treating the query as a generic multi-way join.

Our key observation is that one-hop subqueries have a special property: their output size is bounded by the edge table size, which is public information. This enables a hybrid approach where one-hop patterns are processed with a specialized (faster) operator, while the remaining query structure is handled by general oblivious multi-way joins.


%==============================================================================
\section{System Overview}
\label{sec:overview}
%==============================================================================

This section presents the architecture of \system and illustrates its operation through a running example.

%------------------------------------------------------------------------------
\subsection{Architecture}
\label{sec:overview:arch}
%------------------------------------------------------------------------------

Figure~\ref{fig:architecture} shows the high-level architecture of \system. Given a multi-hop graph query, the system processes it through three main components:

\begin{enumerate}
    \item \textbf{Query Decomposition} (Section~\ref{sec:decomposition}): Analyzes the query to identify one-hop patterns that can be optimized. The decomposer rewrites the original query into a combination of one-hop operations and a reduced query for the remaining joins.

    \item \textbf{\onehop Operator} (Section~\ref{sec:onehop}): Executes one-hop traversals using our novel oblivious algorithm. Each one-hop operation produces output with size equal to the edge table---a publicly known quantity---enabling efficient graph-native processing without information leakage.

    \item \textbf{Oblivious Multi-Way Join}~\cite{TODO}: Handles the reduced query after one-hop operations complete. This component uses existing oblivious join algorithms to process the remaining joins while hiding intermediate result sizes.
\end{enumerate}

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{figures/system-architecture.pdf}
\caption{Architecture of \system. Query decomposition identifies one-hop patterns for optimization. The \onehop operator processes these patterns efficiently, while the oblivious multi-way join handles remaining complexity.}
\label{fig:architecture}
\end{figure}

%------------------------------------------------------------------------------
\subsection{Key Design Decisions}
\label{sec:overview:design}
%------------------------------------------------------------------------------

Three key design decisions underpin our approach:

\paragraph{Public-Sized Outputs from One-Hop.}
The \onehop operator always produces output of size $|E|$, where $E$ is the edge table. Since edge table sizes are public information in our threat model (Section~\ref{sec:background:threat}), this output size reveals nothing new to the adversary. Non-matching tuples are replaced with dummy entries to maintain the fixed size. This property is crucial: it allows us to use faster, graph-native algorithms for one-hop traversals without compromising security.

\paragraph{Composition with Multi-Way Joins.}
The outputs of \onehop operations become inputs to the oblivious multi-way join algorithm. Because these outputs have publicly known sizes, the composition remains secure---the multi-way join algorithm's security guarantees hold when all input sizes are public. This modular design allows us to leverage existing, well-analyzed oblivious join algorithms.

\paragraph{Greedy Decomposition.}
Our query decomposition uses a greedy strategy to select which one-hop patterns to optimize. While optimal decomposition is NP-hard in general, greedy selection works well for common query patterns (chains, stars, trees) and provides consistent speedups in practice.

%------------------------------------------------------------------------------
\subsection{Running Example}
\label{sec:overview:example}
%------------------------------------------------------------------------------

We illustrate \system's operation with a concrete example from financial fraud detection.

\paragraph{Query.} Find pairs of accounts that transacted with each other, where the source account has balance $> 10000$:
\begin{center}
\small
\texttt{MATCH (a1:Account)-[t:Txn]$\rightarrow$(a2:Account)}\\
\texttt{WHERE a1.balance > 10000}\\
\texttt{RETURN a1, t, a2}
\end{center}

\paragraph{Input Tables.}
\begin{itemize}
    \item \texttt{Account}: 10,000 rows with columns \texttt{(id, owner, balance)}
    \item \texttt{Transaction}: 50,000 rows with columns \texttt{(src\_id, dst\_id, amount)}
\end{itemize}

\paragraph{Baseline Execution (No Decomposition).}
Using only the oblivious multi-way join, this query is treated as a three-way join: $\texttt{Account} \bowtie \texttt{Transaction} \bowtie \texttt{Account}$. The algorithm must:
\begin{enumerate}
    \item Build a join tree with three nodes
    \item Execute bottom-up phase: compute multiplicities for all tuples
    \item Execute top-down phase: replicate and align tuples
    \item Apply the filter \texttt{a1.balance > 10000} obliviously
\end{enumerate}
This requires multiple oblivious sorts over the combined data.

\paragraph{Optimized Execution (With \system).}
The query decomposer recognizes this as a single one-hop pattern and routes it entirely to the \onehop operator:
\begin{enumerate}
    \item Build oblivious hash map for \texttt{Account} (filtered by balance $> 10000$)
    \item Sort \texttt{Transaction} by \texttt{src\_id}
    \item Apply duplicate suppression: mark first occurrence of each \texttt{src\_id}
    \item Probe hash map for marked entries only
    \item Forward-fill: propagate results to all transactions with same source
    \item Repeat for destination side
    \item Output: 50,000 rows (padded with dummies for non-matches)
\end{enumerate}

The key difference: \onehop avoids the full multi-way join machinery by exploiting the graph structure. The output size (50,000 = $|$\texttt{Transaction}$|$) is public, so no information leaks.

\paragraph{Multi-Hop Example.}
For longer queries like a 3-hop chain:
\begin{center}
\small
\texttt{(a1:Account)-[t1]$\rightarrow$(a2)-[t2]$\rightarrow$(a3)-[t3]$\rightarrow$(a4:Account)}\\
\texttt{WHERE a1.balance > 10000 AND a4.balance < 1000}
\end{center}

The decomposer creates one hop per transaction edge, with consecutive hops sharing overlapping account nodes:
\begin{enumerate}
    \item $h_1$ = \onehop(\texttt{a1}, \texttt{t1}, \texttt{a2})
    \item $h_2$ = \onehop(\texttt{a2}, \texttt{t2}, \texttt{a3}) --- overlaps with $h_1$ at \texttt{a2}
    \item $h_3$ = \onehop(\texttt{a3}, \texttt{t3}, \texttt{a4}) --- overlaps with $h_2$ at \texttt{a3}
    \item Reduced query: $h_1 \bowtie h_2 \bowtie h_3$
    \item Join conditions: $h_1.\texttt{dest\_id} = h_2.\texttt{src\_id}$ AND $h_2.\texttt{dest\_id} = h_3.\texttt{src\_id}$
    \item Filters distributed to hops: \texttt{a1} filter $\rightarrow$ $h_1$, \texttt{a4} filter $\rightarrow$ $h_3$
\end{enumerate}

The reduced query joins 3 hop tables instead of 7 raw tables. Each hop is an alias over a single pre-computed one-hop table, and the decomposition is independent of where filters are placed.


%==============================================================================
\section{The \onehop Operator}
\label{sec:onehop}
%==============================================================================

This section presents \onehop, our oblivious one-hop operator. We first define the problem, explain why naive approaches fail, then present our algorithm in detail.

%------------------------------------------------------------------------------
\subsection{Problem Definition}
\label{sec:onehop:problem}
%------------------------------------------------------------------------------

\paragraph{Input:}
\begin{itemize}
    \item Source node table $S$ with schema $(id, attr_1, \ldots, attr_s)$
    \item Edge table $E$ with schema $(src\_id, dst\_id, attr_1, \ldots, attr_e)$
    \item Destination node table $D$ with schema $(id, attr_1, \ldots, attr_d)$
    \item Optional predicates $P_S$, $P_E$, $P_D$ on each table
\end{itemize}

\paragraph{Output:}
A table $R$ containing all tuples $(s, e, d)$ where:
\begin{itemize}
    \item $s \in S$ satisfies $P_S$
    \item $e \in E$ satisfies $P_E$ and $e.src\_id = s.id$ and $e.dst\_id = d.id$
    \item $d \in D$ satisfies $P_D$
\end{itemize}

\paragraph{Constraint:}
The output size must equal $|E|$. Non-matching entries are padded with dummy tuples. This ensures the output size is publicly known (edge table sizes are public).

%------------------------------------------------------------------------------
\subsection{Why Naive Approaches Fail}
\label{sec:onehop:naive}
%------------------------------------------------------------------------------

A standard hash join implementation would:
\begin{enumerate}
    \item Build a hash table $H_S$ on source nodes keyed by $id$
    \item For each edge $e$, probe $H_S[e.src\_id]$ to get source attributes
    \item Build a hash table $H_D$ on destination nodes keyed by $id$
    \item For each edge $e$, probe $H_D[e.dst\_id]$ to get destination attributes
\end{enumerate}

\paragraph{The Problem: Degree Leakage.}
This approach leaks node degrees through access patterns. If node $v$ has degree 100 (appears as source in 100 edges), the hash table entry $H_S[v]$ is accessed 100 times. An adversary observing memory accesses can count how many times each hash bucket is probed, revealing the degree distribution of the graph.

Even with oblivious hash tables (which hide \emph{which} bucket is accessed), the \emph{number} of accesses per unique key reveals degree information. Padding to the maximum degree is prohibitively expensive---if the maximum degree is 10,000, we would need $|S| \times 10,000$ accesses.

%------------------------------------------------------------------------------
\subsection{The \onehop Algorithm}
\label{sec:onehop:algorithm}
%------------------------------------------------------------------------------

Our key insight is to \emph{decouple} the number of hash table probes from node degrees using \textbf{duplicate suppression} and \textbf{forward filling}. We probe the hash table once per unique key, then propagate results to all edges sharing that key.

Algorithm~\ref{alg:forwardfill} shows the complete procedure. We describe each phase below.

\begin{algorithm}[t]
\caption{\onehop: Oblivious One-Hop Operator}
\label{alg:forwardfill}
\begin{algorithmic}[1]
\Require Source table $S$, Edge table $E$, Destination table $D$, Predicates $P$
\Ensure Result table $R$ with $|R| = |E|$

\State \textbf{// Phase 1: Forward Pass (Source $\rightarrow$ Edge)}
\State Build oblivious hash map $H_S$ from $S$ (key: $id$)
\State Sort $E$ by $src\_id$
\State Mark first occurrence of each $src\_id$ in $E$
\State For marked entries: probe $H_S$, store result
\State Forward-fill: propagate to all entries with same $src\_id$

\State \textbf{// Phase 2: Reverse Pass (Edge $\rightarrow$ Destination)}
\State Build oblivious hash map $H_D$ from $D$ (key: $id$)
\State Sort $E$ by $dst\_id$
\State Mark first occurrence of each $dst\_id$ in $E$
\State For marked entries: probe $H_D$, store result
\State Forward-fill: propagate to all entries with same $dst\_id$

\State \textbf{// Phase 3: Filter and Output}
\State Evaluate predicates $P$ on all entries (mark matches)
\State Oblivious compaction: move matches to front, pad with dummies
\State \Return Result table $R$ with $|R| = |E|$
\end{algorithmic}
\end{algorithm}

\paragraph{Phase 1: Forward Pass.}
We enrich edges with source node attributes:
\begin{enumerate}
    \item \textbf{Build hash map}: Construct an oblivious hash map $H_S$ containing all source nodes, keyed by node ID. This takes $O(|S|)$ time.

    \item \textbf{Sort edges}: Sort the edge table by $src\_id$ using oblivious sorting. After sorting, all edges from the same source are contiguous.

    \item \textbf{Duplicate suppression}: Scan the sorted edges and mark only the \emph{first} occurrence of each unique $src\_id$. This is a linear pass: compare each entry with its predecessor, mark if different.

    \item \textbf{Probe}: For each marked entry, probe $H_S$ to retrieve source attributes. Unmarked entries skip this step. The number of probes equals the number of \emph{unique} source IDs in $E$, not the number of edges.

    \item \textbf{Forward fill}: Scan the edges linearly, propagating the probe result to all subsequent entries with the same $src\_id$. Each entry copies attributes from the preceding entry if their $src\_id$ matches.
\end{enumerate}

\paragraph{Phase 2: Reverse Pass.}
We repeat the same process for destination nodes:
\begin{enumerate}
    \item Build oblivious hash map $H_D$ for destination nodes
    \item Sort edges by $dst\_id$
    \item Apply duplicate suppression (mark first occurrence of each $dst\_id$)
    \item Probe $H_D$ for marked entries
    \item Forward-fill destination attributes
\end{enumerate}

After this phase, each edge entry contains: edge attributes + source node attributes + destination node attributes.

\paragraph{Phase 3: Filter and Output.}
\begin{enumerate}
    \item \textbf{Evaluate predicates}: Apply all predicates ($P_S$, $P_E$, $P_D$) to every entry. Mark entries that satisfy all predicates as ``real''; others as ``dummy''.

    \item \textbf{Oblivious compaction}: Rearrange entries so real results appear first, followed by dummies. Use oblivious compaction to hide how many entries matched.

    \item \textbf{Output}: Return the table with exactly $|E|$ rows.
\end{enumerate}

%------------------------------------------------------------------------------
\subsection{Correctness}
\label{sec:onehop:correctness}
%------------------------------------------------------------------------------

\begin{theorem}[Correctness]
\onehop produces the same result as a standard three-way equi-join $S \bowtie E \bowtie D$ with predicates applied.
\end{theorem}

\begin{proof}[Proof sketch]
Every edge $e \in E$ appears exactly once in the output. During the forward pass, $e$ receives source attributes from $H_S[e.src\_id]$ if the source exists and satisfies $P_S$; otherwise it receives null/dummy attributes. Similarly for destination attributes in the reverse pass. Predicate evaluation marks exactly those entries where all three components (source, edge, destination) satisfy their respective predicates and the foreign keys match. The compaction preserves all real results while padding to size $|E|$.
\end{proof}

%------------------------------------------------------------------------------
\subsection{Security Analysis}
\label{sec:onehop:security}
%------------------------------------------------------------------------------

\begin{theorem}[Obliviousness]
\onehop is oblivious: its memory access pattern depends only on $|S|$, $|E|$, and $|D|$, not on data values or predicate selectivity.
\end{theorem}

\begin{proof}[Proof sketch]
We analyze each operation:
\begin{itemize}
    \item \textbf{Hash map construction}: Oblivious hash maps have data-independent access patterns by construction.

    \item \textbf{Sorting}: Oblivious sorting (e.g., bitonic sort) has fixed access patterns.

    \item \textbf{Duplicate suppression}: Linear scan comparing adjacent entries---same pattern regardless of data.

    \item \textbf{Probing}: The number of probes equals the number of unique keys \emph{after sorting}, which is hidden by the oblivious hash map. Each probe has fixed access pattern.

    \item \textbf{Forward fill}: Linear scan with fixed access pattern.

    \item \textbf{Predicate evaluation}: Evaluated on all entries regardless of result.

    \item \textbf{Compaction}: Oblivious compaction has data-independent access patterns.
\end{itemize}
The output size is always $|E|$, which is public. No intermediate quantity reveals selectivity or degree distribution.
\end{proof}

%------------------------------------------------------------------------------
\subsection{Complexity Analysis}
\label{sec:onehop:complexity}
%------------------------------------------------------------------------------

\paragraph{Time Complexity.}
\begin{itemize}
    \item Hash map construction: $O(|S| + |D|)$
    \item Sorting (twice): $O(|E| \log |E|)$
    \item Duplicate suppression: $O(|E|)$
    \item Probing: $O(|E|)$ (at most $|E|$ unique keys)
    \item Forward fill: $O(|E|)$
    \item Compaction: $O(|E|)$
\end{itemize}
Total: $O(|E| \log |E| + |S| + |D|)$

\paragraph{Space Complexity.}
$O(|E| + |S| + |D|)$ for storing the tables and hash maps.


%==============================================================================
\section{Query Decomposition}
\label{sec:decomposition}
%==============================================================================

This section presents our query decomposition framework, which rewrites multi-hop queries to maximize the use of \onehop operations.

%------------------------------------------------------------------------------
\subsection{Motivation}
\label{sec:decomposition:motivation}
%------------------------------------------------------------------------------

Consider a 3-hop chain query:
\begin{center}
\small
\texttt{(a1:Account)-[t1]$\rightarrow$(a2)-[t2]$\rightarrow$(a3)-[t3]$\rightarrow$(a4)}\\
\texttt{WHERE a1.balance > 10000 AND a4.balance < 1000}
\end{center}

Without decomposition, this becomes a 7-way join processed entirely by the oblivious multi-way join algorithm. With our filter-independent decomposition, we create one hop per transaction edge:
\begin{enumerate}
    \item $h_1$ = \onehop$(a1, t1, a2)$ --- first hop
    \item $h_2$ = \onehop$(a2, t2, a3)$ --- overlaps with $h_1$ at $a2$
    \item $h_3$ = \onehop$(a3, t3, a4)$ --- overlaps with $h_2$ at $a3$
    \item Join consecutive hops: $h_1.\texttt{dest\_id} = h_2.\texttt{src\_id}$ AND $h_2.\texttt{dest\_id} = h_3.\texttt{src\_id}$
    \item Distribute filters: $a1$ filter $\rightarrow$ $h_1.\texttt{src}$, $a4$ filter $\rightarrow$ $h_3.\texttt{dest}$
\end{enumerate}

All hops are aliases over a single pre-computed one-hop table. The reduced query joins 3 hop tables instead of 7 raw tables. This decomposition is \emph{filter-independent}---the same hop structure is used regardless of where predicates appear, simplifying the algorithm and enabling uniform optimization.

% %------------------------------------------------------------------------------
% \subsection{Decomposition Problem}
% \label{sec:decomposition:problem}
% %------------------------------------------------------------------------------

% \paragraph{Input:}
% A query graph $G_Q = (V_Q, E_Q)$ where:
% \begin{itemize}
%     \item $V_Q$ = node table references (possibly with predicates)
%     \item $E_Q$ = edge table references connecting nodes
% \end{itemize}

% \paragraph{Output:}
% \begin{itemize}
%     \item A set of \onehop operations $\{H_1, \ldots, H_k\}$
%     \item A reduced query $Q'$ over the \onehop outputs and remaining tables
% \end{itemize}

% \paragraph{Goal:}
% Minimize total execution cost while maintaining correctness and security.

% %------------------------------------------------------------------------------
% \subsection{Decomposition Algorithm}
% \label{sec:decomposition:algorithm}
% %------------------------------------------------------------------------------

% Algorithm~\ref{alg:decompose} shows our greedy decomposition procedure.

% \begin{algorithm}[t]
% \caption{Query Decomposition}
% \label{alg:decompose}
% \begin{algorithmic}[1]
% \Require Query graph $G_Q = (V_Q, E_Q)$
% \Ensure Set of \onehop operations, reduced query $Q'$

% \State $\mathcal{H} \leftarrow \emptyset$ \Comment{Set of 1-hop operations}
% \State $\mathcal{T} \leftarrow$ identify all $(node, edge, node)$ triplets in $G_Q$

% \For{each triplet $T = (n_1, e, n_2) \in \mathcal{T}$}
%     \State $score(T) \leftarrow$ compute optimization potential
% \EndFor

% \State Sort $\mathcal{T}$ by score (descending)

% \For{each triplet $T = (n_1, e, n_2)$ in sorted order}
%     \If{$T$ does not overlap with any triplet in $\mathcal{H}$}
%         \State $\mathcal{H} \leftarrow \mathcal{H} \cup \{T\}$
%         \State Execute $H_T \leftarrow$ \onehop$(n_1, e, n_2)$
%     \EndIf
% \EndFor

% \State Construct $Q'$ by replacing each $T \in \mathcal{H}$ with $H_T$
% \STATE \RETURN $\mathcal{H}$, $Q'$
% \end{algorithmic}
% \end{algorithm}

% \paragraph{Scoring Triplets.}
% We score each triplet based on its optimization potential:
% \begin{itemize}
%     \item \textbf{Has filter predicates}: Triplets containing filtered nodes score higher, as \onehop can apply filters efficiently.
%     \item \textbf{Reduces join width}: Triplets that replace more tables in the join score higher.
%     \item \textbf{Edge table size}: Larger edge tables benefit more from \onehop's efficiency.
% \end{itemize}

% \paragraph{Non-Overlapping Selection.}
% Two triplets \emph{overlap} if they share an edge table. We select triplets greedily, skipping any that overlap with already-selected ones. This ensures each edge table is processed at most once.

%------------------------------------------------------------------------------
\subsection{Example: Chain Query Decomposition}
\label{sec:decomposition:example}
%------------------------------------------------------------------------------

\begin{figure}[t]
\centering
\small
\begin{verbatim}
Original Query (3-hop chain):
  (a1)--[t1]-->(a2)--[t2]-->(a3)--[t3]-->(a4)

Filter-Independent Decomposition (one hop per edge):
  h1 = (a1)--[t1]-->(a2)
  h2 = (a2)--[t2]-->(a3)   [overlaps with h1 at a2]
  h3 = (a3)--[t3]-->(a4)   [overlaps with h2 at a3]

After decomposition:
  h1 = ForwardFill(a1, t1, a2)  [size = |txn|]
  h2 = ForwardFill(a2, t2, a3)  [size = |txn|]
  h3 = ForwardFill(a3, t3, a4)  [size = |txn|]

Reduced query: h1 JOIN h2 JOIN h3
  WHERE h1.dest_id = h2.src_id
    AND h2.dest_id = h3.src_id
\end{verbatim}
\caption{Filter-independent decomposition of a 3-hop chain query. Every transaction edge becomes a hop, with consecutive hops sharing overlapping account nodes. All hops are aliases over a single pre-computed one-hop table.}
\label{fig:decomposition}
\end{figure}

Figure~\ref{fig:decomposition} illustrates the filter-independent decomposition of a 3-hop chain query. Each transaction edge becomes a hop, and consecutive hops share overlapping account nodes (the destination of one hop equals the source of the next). The reduced query joins these hops on their shared account IDs.

%------------------------------------------------------------------------------
\subsection{Correctness and Optimality}
\label{sec:decomposition:correctness}
%------------------------------------------------------------------------------

\paragraph{Correctness.}
The decomposition is correct because each \onehop computes exactly the same result as the corresponding three-way join, and consecutive hops are joined on their shared account node. For a chain query with $k$ transaction edges, the decomposition produces $k$ hops joined on $k-1$ overlapping account nodes, which is equivalent to the original $(2k+1)$-way join.

\paragraph{Determinism.}
Unlike greedy decomposition approaches that must choose which triplets to optimize, our filter-independent decomposition is deterministic: every transaction edge becomes exactly one hop. This simplifies the algorithm (no scoring or selection logic) and ensures consistent behavior regardless of predicate placement. The decomposition handles both chain and branch query patterns uniformly---branch nodes simply connect to multiple hops via their shared account ID.


%==============================================================================
\section{Security Analysis}
\label{sec:security}
%==============================================================================

This section provides an informal security argument for the complete \system pipeline.

%------------------------------------------------------------------------------
\subsection{Security Claim}
\label{sec:security:claim}
%------------------------------------------------------------------------------

\begin{theorem}[Security]
The complete \system pipeline (decomposition + \onehop + multi-way join) leaks only information that is public by our threat model:
\begin{enumerate}
    \item Base table sizes ($|S|$, $|E|$, $|D|$, etc.)
    \item Query structure (which tables are joined, predicates)
    \item Final output size
\end{enumerate}
\end{theorem}

%------------------------------------------------------------------------------
\subsection{Argument}
\label{sec:security:argument}
%------------------------------------------------------------------------------

\paragraph{\onehop Security.}
As shown in Section~\ref{sec:onehop:security}, each \onehop operation is oblivious. The output size equals the edge table size, which is public. Key properties:
\begin{itemize}
    \item Duplicate suppression hides node degrees
    \item Forward fill has data-independent access patterns
    \item Output padding hides predicate selectivity
\end{itemize}

\paragraph{Composition Security.}
The outputs of \onehop operations become inputs to the oblivious multi-way join. Because:
\begin{enumerate}
    \item Each \onehop output has a publicly known size (= edge table size)
    \item The multi-way join algorithm~\cite{TODO} is proven secure when input sizes are public
\end{enumerate}
The composition remains secure. The multi-way join sees inputs of known sizes and produces output while hiding intermediate results.

\paragraph{Decomposition Security.}
Query decomposition is a compile-time transformation based on query structure (public). It does not depend on data values. The choice of which triplets to optimize is deterministic given the query, revealing nothing about the data.

%------------------------------------------------------------------------------
\subsection{What Is Not Leaked}
\label{sec:security:notleaked}
%------------------------------------------------------------------------------

The following remain hidden from the adversary:
\begin{itemize}
    \item \textbf{Data values}: Actual node/edge properties
    \item \textbf{Predicate selectivity}: What fraction of rows satisfy filters
    \item \textbf{Node degrees}: How many edges each node has
    \item \textbf{Join selectivity}: How many tuples actually match
    \item \textbf{Intermediate cardinalities}: Sizes of partial results during multi-way join
\end{itemize}


%==============================================================================
\section{Evaluation}
\label{sec:evaluation}
%==============================================================================

We evaluate \system on financial transaction workloads, comparing decomposed execution against baseline oblivious multi-way joins.

%------------------------------------------------------------------------------
\subsection{Experimental Setup}
\label{sec:evaluation:setup}
%------------------------------------------------------------------------------

\paragraph{Hardware.}
Intel Xeon processor with TDX support, 128GB RAM, running Ubuntu 22.04.

\paragraph{Dataset.}
Banking transaction graph with:
\begin{itemize}
    \item \texttt{Account} nodes: varying from 1K to 100K
    \item \texttt{Transaction} edges: 5$\times$ the number of accounts
    \item Properties: account balance, transaction amount, timestamps
\end{itemize}

\paragraph{Queries.}
\begin{itemize}
    \item \textbf{Chain queries}: 2-hop to 5-hop linear patterns
    \item \textbf{Branch queries}: Star patterns with central node
    \item All queries include filter predicates on endpoint nodes
\end{itemize}

\paragraph{Baselines.}
\begin{itemize}
    \item \textbf{No Decomposition}: All tables processed by oblivious multi-way join
    \item \textbf{With Decomposition}: \system's hybrid approach
\end{itemize}

%------------------------------------------------------------------------------
\subsection{End-to-End Performance}
\label{sec:evaluation:e2e}
%------------------------------------------------------------------------------

Table~\ref{tab:e2e} shows end-to-end query execution times.

\begin{table}[t]
\centering
\caption{End-to-end performance comparison (10K accounts, 50K transactions)}
\label{tab:e2e}
\begin{tabular}{lrrr}
\toprule
\textbf{Query} & \textbf{No Decomp} & \textbf{With Decomp} & \textbf{Speedup} \\
\midrule
4-hop chain & 11.53s & 6.94s & 1.66$\times$ \\
branch & 23.03s & 16.97s & 1.35$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Findings.}
\begin{itemize}
    \item \system achieves 1.35--1.66$\times$ speedup on these queries
    \item Chain queries benefit more than branch queries from decomposition
    \item The one-hop operator contributes only 0.17s of the 6.94s decomposed time (2.5\%), with most time in the reduced multi-way join
\end{itemize}

% %------------------------------------------------------------------------------
% \subsection{Breakdown Analysis}
% \label{sec:evaluation:breakdown}
% %------------------------------------------------------------------------------

% Figure~\ref{fig:breakdown} shows the time breakdown for a 4-hop chain query.

% \begin{figure}[t]
% \centering
% \small
% \begin{verbatim}
% 4-hop chain query breakdown (10K accounts):

% No Decomposition:
%   [======= Multi-way Join: 11.53s =======]

% With Decomposition:
%   [1-hop][======= Reduced MWJ =======]
%    0.17s          6.77s
%               Total: 6.94s
% \end{verbatim}
% \caption{Time breakdown for 4-hop chain query. The \onehop operation is extremely fast (0.17s), while the main benefit comes from the reduced multi-way join operating on fewer tables.}
% \label{fig:breakdown}
% \end{figure}

% The \onehop operation (0.17s) is nearly negligible compared to the join time. The key benefit is that the reduced multi-way join (6.77s) operates on the decomposed query structure, which is faster than the original 7-table join (11.53s).

%------------------------------------------------------------------------------
\subsection{Scaling Experiments}
\label{sec:evaluation:scaling}
%------------------------------------------------------------------------------

\paragraph{Scaling with Data Size.}
Table~\ref{tab:scaling} shows performance as data size increases.

\begin{table}[t]
\centering
\caption{Scaling with data size (4-hop chain query)}
\label{tab:scaling}
\begin{tabular}{rrrr}
\toprule
\textbf{Accounts} & \textbf{No Decomp} & \textbf{With Decomp} & \textbf{Speedup} \\
\midrule
1K & 0.68s & 0.40s & 1.67$\times$ \\
2K & 1.39s & 0.74s & 1.86$\times$ \\
5K & 4.09s & 3.50s & 1.16$\times$ \\
10K & 11.53s & 6.94s & 1.66$\times$ \\
20K & 22.01s & 14.62s & 1.50$\times$ \\
50K & 70.00s & 36.87s & 1.89$\times$ \\
\bottomrule
\end{tabular}
\end{table}

Speedup ranges from 1.16$\times$ to 1.89$\times$ across different scales, with an average of approximately 1.6$\times$. The variation is due to cache effects and the relative cost of different phases at different scales.

\paragraph{One-Hop Overhead.}
The one-hop operator time scales linearly with data size: 0.01s at 1K accounts to 1.01s at 50K accounts, representing only 1--3\% of total decomposed execution time.

Figure~\ref{fig:scaling} visualizes the scaling behavior for both query types. The decomposed approach (blue) consistently outperforms the non-decomposed baseline (red), with speedup annotations showing the improvement ratio at each scale.

\begin{figure*}[t]
\centering
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/scaling_chain4.png}
    (a) 4-hop chain query
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/scaling_branch.png}
    (b) Branch query
\end{minipage}
\caption{Scaling performance: Non-decomposed (red) vs decomposed (blue) execution time as data size increases. Speedup annotations show the ratio at each scale.}
\label{fig:scaling}
\end{figure*}


%==============================================================================
\section{Related Work}
\label{sec:related}
%==============================================================================

%------------------------------------------------------------------------------
\subsection{Oblivious Database Systems}
\label{sec:related:oblivious}
%------------------------------------------------------------------------------

\paragraph{ORAM-Based Approaches.}
Oblivious RAM~\cite{oram-goldreich} provides general-purpose oblivious memory access but incurs $O(\log N)$ overhead per access. Systems like Oblix~\cite{oblix} and Opaque~\cite{opaque} use ORAM for oblivious database operations. Our work avoids ORAM overhead by designing algorithms with inherently oblivious access patterns.

\paragraph{Oblivious Relational Operators.}
Prior work has developed oblivious versions of relational operators: sorting~\cite{oblivious-sort}, filtering, aggregation, and joins~\cite{oblivious-join}. We build on oblivious multi-way join algorithms~\cite{TODO} but introduce graph-specific optimizations.

%------------------------------------------------------------------------------
\subsection{Secure Graph Processing}
\label{sec:related:graph}
%------------------------------------------------------------------------------

\paragraph{Encrypted Graph Databases.}
Systems like encrypted Neo4j variants protect data at rest but do not hide access patterns during query execution.

\paragraph{TEE-Based Graph Analytics.}
GraphSC~\cite{graphsc} and similar systems run graph analytics (PageRank, shortest paths) inside secure enclaves. These focus on iterative algorithms, not pattern-matching queries. Our work targets the latter.

\paragraph{Oblivious Graph Algorithms.}
Prior work on oblivious graph algorithms focuses on specific computations (BFS, DFS, shortest paths). We address the more general problem of pattern-matching queries with predicates.

%------------------------------------------------------------------------------
\subsection{Graph Query Optimization}
\label{sec:related:optimization}
%------------------------------------------------------------------------------

Traditional graph query optimization focuses on join ordering, indexing, and caching---none of which consider obliviousness. Query decomposition appears in distributed graph processing but without security constraints. To our knowledge, \system is the first to combine graph-native query optimization with oblivious execution.


%==============================================================================
\section{Conclusion}
\label{sec:conclusion}
%==============================================================================

We presented \system, an oblivious property graph database that exploits graph structure for efficient secure query processing. Our key contributions are:

\begin{enumerate}
    \item \textbf{\onehop}: An oblivious one-hop operator that uses duplicate suppression and forward filling to achieve data-independent access patterns. By producing output of publicly known size (= edge table size), \onehop enables graph-native optimization without information leakage.

    \item \textbf{Query Decomposition}: A framework that rewrites multi-hop queries to maximize \onehop usage, reducing the work for oblivious multi-way joins.

    \item \textbf{Evaluation}: Experiments on financial transaction workloads showing 1.2--1.9$\times$ speedup over baseline oblivious execution while maintaining identical security guarantees.
\end{enumerate}

\system demonstrates that graph-specific optimizations are compatible with oblivious execution. Future work includes extending to cyclic query patterns, developing cost-based decomposition, and supporting additional graph operations.


%==============================================================================
% References
%==============================================================================
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
